{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.language_modeling import LanguageModelingModel, LanguageModelingArgs\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = {'fp16': False, 'use_multiprocessing': False, 'reprocess_input_data': False, 'overwrite_output_dir': True, 'num_train_epochs': 1, 'save_eval_checkpoints': False, 'save_model_every_epoch': True, 'learning_rate': 1e-05, 'warmup_steps': 1000, 'train_batch_size': 64, 'eval_batch_size': 64, 'gradient_accumulation_steps': 1, 'block_size': 130, 'max_seq_length': 130, 'dataset_type': 'simple', 'logging_steps': 500, 'evaluate_during_training': True, 'evaluate_during_training_steps': 500, 'evaluate_during_training_steps_anomaly': 500, 'anomaly_batch_size': 64, 'evaluate_during_training_verbose': True, 'use_cached_eval_features': True, 'sliding_window': True, 'vocab_size': 52000, 'eval_anomalies': True, 'random_generator': 1, 'use_rtd_loss': True, 'rtd_loss_weight': 50, 'rmd_loss_weight': 100, 'mlm_loss_weight': 1, 'dump_histogram': 0, 'eval_anomaly_after': 0, 'train_just_generator': 0, 'replace_tokens': 0, 'extract_scores': 1, 'subset_name': 'known', 'extract_repr': 0, 'train_document': True, 'tokenizer_name': 'bert-base-uncased', 'tensorboard_dir': 'runs/tests/known_slen128_wd0.1_lr1e-05-0.0001_msk50_p50_dl4_sz256_gl1_sz16_rgen1_drop0.5_w50_100_1_replace0_mlmr1_07232023_155706_cont0', 'extract_reps': 0, 'weight_decay': 0.1, 'optimizer': 'AdamW', 'scores_export_path': './token_scores/known_slen128_wd0.1_lr1e-05-0.0001_msk50_p50_dl4_sz256_gl1_sz16_rgen1_drop0.5_w50_100_1_replace0_mlmr1_07232023_155706_cont0/', 'generator_config': {'embedding_size': 128, 'hidden_size': 16, 'num_hidden_layers': 1}, 'discriminator_config': {'hidden_dropout_prob': 0.5, 'attention_probs_dropout_prob': 0.5, 'embedding_size': 128, 'hidden_size': 256, 'num_hidden_layers': 4}, 'mlm_lr_ratio': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_ = pickle.load(open('/home/anhnmt2/Documents/CodeInjection/date/experiments/pseudo_labels128_p50.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN MODEL: RANDOM GENERATOR: 1\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModelingModel(\n",
    "    \"electra\", \n",
    "    # '/home/anhnmt2/Documents/CodeInjection/date/experiments/outputs',\n",
    "    None,\n",
    "    args=train_args,\n",
    "    masks=masks_, \n",
    "    use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.load_state_dict(torch.load('/home/anhnmt2/Documents/CodeInjection/date/experiments/outputs/pytorch_model.bin'))\n",
    "model.model.generator_model.load_state_dict(torch.load('/home/anhnmt2/Documents/CodeInjection/date/experiments/outputs/generator_model/pytorch_model.bin'))\n",
    "model.model.discriminator_model.load_state_dict(torch.load('/home/anhnmt2/Documents/CodeInjection/date/experiments/outputs/discriminator_model/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"/home/anhnmt2/Documents/CodeInjection/date/datasets/web_attack_subset/test/known.txt\"\n",
    "test_file_outliers = \"/home/anhnmt2/Documents/CodeInjection/date/datasets/web_attack_subset/test/known-outliers.txt\"\n",
    "eval_dataset, eval_doc_dataset, eval_doc_dataset_outliers = model.custom_prepare_eval_data(test_file, test_file_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inlier_sc:   0%|          | 0/286 [00:00<?, ?it/s]/home/anhnmt2/.local/lib/python3.6/site-packages/simpletransformers/language_modeling/language_modeling_utils.py:215: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits = F.softmax(predict)\n",
      "/home/anhnmt2/.local/lib/python3.6/site-packages/simpletransformers/language_modeling/language_modeling_utils.py:229: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits = F.softmax(predict)\n",
      "inlier_sc: 100%|██████████| 286/286 [00:22<00:00, 12.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# res_out = model.custom_eval_model_anomaly(eval_doc_dataset_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 40.46348680024381,\n",
       " 'loss_rtd': 0.024745863224086645,\n",
       " 'loss_rmd': 0.39226193713688556,\n",
       " 'acc': 0.9681724525474527,\n",
       " 'f1': 0.9837075928799457,\n",
       " 'gt': array([ 0., 44., 10., 26., 22., 19., 22.,  7., 40., 43.,  8., 22.,  3.,\n",
       "        24., 28., 11., 31., 49.,  0., 31., 36., 12., 45., 19., 48., 26.,\n",
       "         5., 33.,  2., 30., 35.,  6., 33., 29., 31., 27.,  7., 46., 22.,\n",
       "        32., 34.,  1.], dtype=float32),\n",
       " 'pred': array([31, 44, 10, 26, 22, 19, 22,  7, 40, 43,  8, 22,  3, 24, 28, 11, 31,\n",
       "        49, 31, 31, 36, 29, 45, 19, 48, 26,  5, 33,  2, 30, 35,  6, 33, 29,\n",
       "        31, 27,  7, 46, 22, 32, 34,  1]),\n",
       " 'loss_gen': 10.493164742743218}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inlier_sc: 100%|██████████| 94/94 [00:07<00:00, 12.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# res_in = model.custom_eval_model_anomaly(eval_doc_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 47.556491501787875,\n",
       " 'loss_rtd': 0.008511082769589538,\n",
       " 'loss_rmd': 0.47130937581049637,\n",
       " 'acc': 0.9311835106382979,\n",
       " 'f1': 0.9641529314509574,\n",
       " 'gt': array([ 4., 14.,  6., 24., 45.,  2.,  4., 25.,  7.,  2.,  0., 21., 34.,\n",
       "        41., 11., 27., 33., 31., 12., 49., 42., 42., 13., 24., 37., 46.,\n",
       "        31., 48.,  2., 40., 35., 20., 30., 47., 39., 18., 38., 28., 29.,\n",
       "        15., 19., 22.,  9., 12.,  1., 15., 18., 26.], dtype=float32),\n",
       " 'pred': array([ 4, 31,  6, 24, 45,  2,  4, 25,  7,  2,  2, 21, 34, 41, 11, 27, 33,\n",
       "        31, 12, 49, 42, 42, 13, 24, 37, 46, 31, 48,  2, 40, 35, 20, 30, 47,\n",
       "        32, 18, 38, 28, 29, 15, 19, 22,  9, 12,  1, 15, 18, 26]),\n",
       " 'loss_gen': 10.434902018689094}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788699246090542"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(test_file, 'r') as f:\n",
    "#     data_in = f.read().splitlines()\n",
    "# with open(test_file_outliers, 'r') as f:\n",
    "#     data_out = f.read().splitlines()\n",
    "\n",
    "# #weighted f1_score\n",
    "# f1_final = (len(data_in)/(len(data_in)+len(data_out)) * res_in['f1']) + (len(data_out)/(len(data_in)+len(data_out)) * res_out['f1'])\n",
    "# f1_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_file) as f:\n",
    "    inlier_len = len(f.readlines())\n",
    "with open(test_file_outliers) as f:\n",
    "    outlier_len = len(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "outlier_sc_doc:   0%|          | 0/286 [00:00<?, ?it/s]/home/anhnmt2/.local/lib/python3.6/site-packages/simpletransformers/language_modeling/language_modeling_model.py:687: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out_softmax = F.softmax(d_output).cpu().numpy()\n",
      "/home/anhnmt2/.local/lib/python3.6/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "outlier_sc_doc: 100%|██████████| 286/286 [00:51<00:00,  5.56it/s]\n",
      "inlier_sc_doc: 100%|██████████| 94/94 [00:16<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NE\n",
      "ROC-AUC    : 0.697778\n",
      "PR-AUC-in  : 0.412344\n",
      "PR-AUC-out : 0.814464\n",
      "Accuracy : 0.719457\n",
      "F1-score : 0.665997\n",
      "PL\n",
      "ROC-AUC    : 0.697861\n",
      "PR-AUC-in  : 0.412359\n",
      "PR-AUC-out : 0.815058\n",
      "Accuracy : 0.719540\n",
      "F1-score : 0.665938\n",
      "MP\n",
      "ROC-AUC    : 0.697759\n",
      "PR-AUC-in  : 0.412341\n",
      "PR-AUC-out : 0.814337\n",
      "Accuracy : 0.719540\n",
      "F1-score : 0.665938\n",
      "NE_RTD\n",
      "ROC-AUC    : 0.836142\n",
      "PR-AUC-in  : 0.627089\n",
      "PR-AUC-out : 0.920035\n",
      "Accuracy : 0.767770\n",
      "F1-score : 0.730202\n",
      "PL_RTD\n",
      "ROC-AUC    : 0.545431\n",
      "PR-AUC-in  : 0.317497\n",
      "PR-AUC-out : 0.743339\n",
      "Accuracy : 0.576588\n",
      "F1-score : 0.531472\n",
      "MP_RTD\n",
      "ROC-AUC    : 0.839628\n",
      "PR-AUC-in  : 0.628130\n",
      "PR-AUC-out : 0.924393\n",
      "Accuracy : 0.768235\n",
      "F1-score : 0.731905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NE/inlier_mean': 1.9729407580296199,\n",
       " 'MP/inlier_mean': 0.9543428004812449,\n",
       " 'PL/inlier_mean': 0.9514241382436691,\n",
       " 'NE/outlier_mean': 1.9938157511784111,\n",
       " 'MP/outlier_mean': 0.992243472929818,\n",
       " 'PL/outlier_mean': 0.9909524799453966,\n",
       " 'NE/mean': 1.9833782546040155,\n",
       " 'MP/mean': 0.9732931367055314,\n",
       " 'PL/mean': 0.9711883090945328,\n",
       " 'NE/roc_auc': 0.6977780501835313,\n",
       " 'NE/pr_auc_in': 0.4123436482735688,\n",
       " 'NE/pr_auc_out': 0.814464125775341,\n",
       " 'PL/roc_auc': 0.6978605799959824,\n",
       " 'PL/pr_auc_in': 0.4123592290184622,\n",
       " 'PL/pr_auc_out': 0.81505784733997,\n",
       " 'MP/roc_auc': 0.6977593181029602,\n",
       " 'MP/pr_auc_in': 0.4123406761905741,\n",
       " 'MP/pr_auc_out': 0.8143371959158469,\n",
       " 'NE_RTD/roc_auc': 0.8361419839186085,\n",
       " 'NE_RTD/pr_auc_in': 0.6270892952266202,\n",
       " 'NE_RTD/pr_auc_out': 0.9200351662377966,\n",
       " 'PL_RTD/roc_auc': 0.5454307739367045,\n",
       " 'PL_RTD/pr_auc_in': 0.3174973440716895,\n",
       " 'PL_RTD/pr_auc_out': 0.743338827764951,\n",
       " 'MP_RTD/roc_auc': 0.8396279333077667,\n",
       " 'MP_RTD/pr_auc_in': 0.6281295810055307,\n",
       " 'MP_RTD/pr_auc_out': 0.9243925078256282}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inlier_len = inlier_len\n",
    "model.outlier_len = outlier_len\n",
    "model.global_step = 0 # Do nothing but still required\n",
    "model.custom_eval_model_document(eval_doc_dataset, eval_doc_dataset_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
